// Custom Ternary Convolution Layer
// Demonstrates building custom quantized layers from scratch

layer CustomTernaryConv2d {
    params {
        in_channels: int
        out_channels: int
        kernel_size: int
        stride: int = 1
        padding: int = 0
        dilation: int = 1
        groups: int = 1
        bias: bool = true
        quantization_method: str = "learned_threshold"
    }
    
    // Learnable weight parameters
    param weight: Tensor {
        shape: [out_channels, in_channels // groups, kernel_size, kernel_size]
        init: "kaiming_normal"
        fan_mode: "fan_out"
    }
    
    param bias: if (bias) Tensor {
        shape: [out_channels]
        init: "zeros"
    }
    
    // Learnable quantization threshold (per output channel)
    param threshold: Tensor {
        shape: [out_channels, 1, 1, 1]
        init: "constant"
        value: 0.5
        requires_grad: true
    }
    
    // Learnable scaling factor for ternary values
    param alpha: Tensor {
        shape: [out_channels, 1, 1, 1]
        init: "ones"
        requires_grad: true
    }
    
    // Training statistics
    state running_mean: Tensor {
        shape: [out_channels]
        init: "zeros"
        requires_grad: false
    }
    
    state running_std: Tensor {
        shape: [out_channels]
        init: "ones"
        requires_grad: false
    }
    
    state num_batches_tracked: int = 0
    
    forward(x: Tensor) -> Tensor {
        if self.training {
            // Training mode: compute statistics and quantize
            weight_ternarized = self.quantize_weights_training(weight, threshold, alpha)
        } else {
            // Inference mode: use cached ternary weights
            weight_ternarized = self.quantize_weights_inference(weight, threshold, alpha)
        }
        
        // Standard convolution with ternary weights
        output = conv2d(
            x, 
            weight_ternarized, 
            bias, 
            stride, 
            padding, 
            dilation, 
            groups
        )
        
        return output
    }
    
    // Quantization during training with STE
    function quantize_weights_training(
        weight: Tensor,
        threshold: Tensor,
        alpha: Tensor
    ) -> Tensor {
        // Normalize threshold to [0, 1]
        t = sigmoid(threshold)
        
        // Compute per-channel statistics
        w_abs = abs(weight)
        w_channel_mean = mean(w_abs, dim: [1, 2, 3], keepdim: true)
        
        // Update running statistics (exponential moving average)
        if self.training {
            momentum = 0.1
            self.running_mean = (1 - momentum) * self.running_mean + momentum * squeeze(w_channel_mean)
            
            w_channel_std = std(weight, dim: [1, 2, 3], keepdim: true)
            self.running_std = (1 - momentum) * self.running_std + momentum * squeeze(w_channel_std)
            
            self.num_batches_tracked += 1
        }
        
        // Adaptive threshold based on channel statistics
        adaptive_threshold = t * w_channel_mean
        
        // Compute scale factor for non-zero values
        mask = (w_abs > adaptive_threshold).float()
        scale = alpha * mean(w_abs * mask, dim: [1, 2, 3], keepdim: true) / (mean(mask) + 1e-7)
        
        // Ternarize: {-scale, 0, scale}
        w_ternary = sign(weight) * scale * mask
        
        // Straight-Through Estimator: pass gradients through
        # In PyTorch this is: w_ternary = w_ternary + (weight - weight.detach())
        w_ternary = w_ternary + (weight - stop_gradient(weight))
        
        return w_ternary
    }
    
    // Quantization during inference (deterministic)
    function quantize_weights_inference(
        weight: Tensor,
        threshold: Tensor,
        alpha: Tensor
    ) -> Tensor {
        t = sigmoid(threshold)
        
        // Use running statistics
        w_channel_mean = unsqueeze(self.running_mean, [1, 2, 3])
        adaptive_threshold = t * w_channel_mean
        
        w_abs = abs(weight)
        mask = (w_abs > adaptive_threshold).float()
        
        scale = alpha * mean(w_abs * mask, dim: [1, 2, 3], keepdim: true) / (mean(mask) + 1e-7)
        w_ternary = sign(weight) * scale * mask
        
        return w_ternary
    }
    
    // Additional methods
    method reset_parameters() {
        // Kaiming initialization for weights
        kaiming_normal_(self.weight, mode: "fan_out", nonlinearity: "relu")
        
        if self.bias is not None {
            zeros_(self.bias)
        }
        
        // Initialize threshold based on weight distribution
        with no_grad() {
            w_abs_mean = mean(abs(self.weight), dim: [1, 2, 3], keepdim: true)
            self.threshold = inverse_sigmoid(w_abs_mean / 2)
        }
    }
    
    method extra_repr() -> str {
        return (
            f"in_channels={in_channels}, out_channels={out_channels}, "
            f"kernel_size={kernel_size}, stride={stride}, padding={padding}, "
            f"quantization_method={quantization_method}"
        )
    }
    
    method get_quantization_stats() -> dict {
        """Return statistics about quantization"""
        with no_grad() {
            w_ternary = self.quantize_weights_inference(weight, threshold, alpha)
            
            // Count ternary values
            num_negative = sum((w_ternary < -1e-6).float())
            num_zero = sum((abs(w_ternary) < 1e-6).float())
            num_positive = sum((w_ternary > 1e-6).float())
            total = product(w_ternary.shape)
            
            return {
                "negative_ratio": num_negative / total,
                "zero_ratio": num_zero / total,
                "positive_ratio": num_positive / total,
                "avg_threshold": mean(sigmoid(threshold)),
                "avg_alpha": mean(alpha),
                "sparsity": num_zero / total
            }
        }
    }
}

// Custom Ternary Linear Layer
layer CustomTernaryLinear {
    params {
        in_features: int
        out_features: int
        bias: bool = true
        quantization_method: str = "learned_threshold"
    }
    
    param weight: Tensor {
        shape: [out_features, in_features]
        init: "kaiming_uniform"
    }
    
    param bias: if (bias) Tensor {
        shape: [out_features]
        init: "zeros"
    }
    
    param threshold: Tensor {
        shape: [out_features, 1]
        init: "constant"
        value: 0.5
        requires_grad: true
    }
    
    param alpha: Tensor {
        shape: [out_features, 1]
        init: "ones"
        requires_grad: true
    }
    
    forward(x: Tensor) -> Tensor {
        // Quantize weights
        t = sigmoid(threshold)
        w_abs = abs(weight)
        w_mean = mean(w_abs, dim: 1, keepdim: true)
        
        adaptive_threshold = t * w_mean
        mask = (w_abs > adaptive_threshold).float()
        
        scale = alpha * mean(w_abs * mask, dim: 1, keepdim: true) / (mean(mask, dim: 1, keepdim: true) + 1e-7)
        w_ternary = sign(weight) * scale * mask
        
        // STE
        if self.training {
            w_ternary = w_ternary + (weight - stop_gradient(weight))
        }
        
        // Linear transformation
        return linear(x, w_ternary, bias)
    }
}

// Custom Activation Quantization
layer TernaryActivation {
    params {
        method: str = "sign"  // "sign" or "adaptive"
        learnable: bool = true
    }
    
    param threshold: if (learnable) Tensor {
        shape: [1]
        init: "constant"
        value: 0.0
        requires_grad: true
    }
    
    forward(x: Tensor) -> Tensor {
        if method == "sign" {
            // Simple sign activation with threshold
            t = threshold if learnable else 0.0
            activated = where(x > t, 1.0, where(x < -t, -1.0, 0.0))
        } else {
            // Adaptive activation
            t = sigmoid(threshold) if learnable else 0.5
            x_abs = abs(x)
            x_max = max(x_abs)
            adaptive_t = t * x_max
            
            mask = (x_abs > adaptive_t).float()
            activated = sign(x) * mask
        }
        
        // STE for gradients
        if self.training {
            activated = activated + (x - stop_gradient(x))
        }
        
        return activated
    }
}

// Example Model using Custom Layers
model CustomTernaryNet {
    num_classes: 10
    
    layer conv1: CustomTernaryConv2d {
        in_channels: 3
        out_channels: 64
        kernel_size: 3
        padding: 1
        quantization_method: "learned_threshold"
    }
    
    layer bn1: BatchNorm2d { num_features: 64 }
    layer act1: TernaryActivation { method: "adaptive", learnable: true }
    
    layer conv2: CustomTernaryConv2d {
        in_channels: 64
        out_channels: 128
        kernel_size: 3
        padding: 1
    }
    
    layer bn2: BatchNorm2d { num_features: 128 }
    layer act2: TernaryActivation { method: "adaptive", learnable: true }
    
    layer avgpool: AdaptiveAvgPool2d { output_size: (1, 1) }
    
    layer fc: CustomTernaryLinear {
        in_features: 128
        out_features: num_classes
    }
    
    forward(x: Tensor) -> Tensor {
        x = conv1(x)
        x = bn1(x)
        x = act1(x)
        
        x = conv2(x)
        x = bn2(x)
        x = act2(x)
        
        x = avgpool(x)
        x = flatten(x, 1)
        x = fc(x)
        
        return x
    }
    
    method get_quantization_report() -> str {
        """Generate comprehensive quantization report"""
        report = "Quantization Statistics:\n"
        report += "=" * 50 + "\n"
        
        for name, layer in self.named_modules() {
            if isinstance(layer, CustomTernaryConv2d) or isinstance(layer, CustomTernaryLinear) {
                stats = layer.get_quantization_stats()
                report += f"\n{name}:\n"
                report += f"  Negative weights: {stats['negative_ratio']:.2%}\n"
                report += f"  Zero weights: {stats['zero_ratio']:.2%}\n"
                report += f"  Positive weights: {stats['positive_ratio']:.2%}\n"
                report += f"  Sparsity: {stats['sparsity']:.2%}\n"
                report += f"  Avg threshold: {stats['avg_threshold']:.4f}\n"
                report += f"  Avg scale (alpha): {stats['avg_alpha']:.4f}\n"
            }
        }
        
        return report
    }
}

// Example usage:
// triton compile custom_conv.triton --output custom_conv.py
// python custom_conv.py --train --dataset cifar10 --epochs 100
// python custom_conv.py --quantization-report --checkpoint best.pth
